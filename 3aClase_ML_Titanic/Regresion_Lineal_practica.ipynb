{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Lineal\n",
    "\n",
    "\n",
    "En este notebook vamos a ir construyendo las funciones que nos permiten hacer regresión lineal y las aplicaremos a casos sencillos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precauciones.\n",
    "\n",
    "Ten cuidado con las dimensiones de los vectores y matrices con los que trabajas. Asegurate de que mantienes la coherencia en las operaciones matriciales. No es lo mismo trabajar con un vector de dimensiones `(n_shape, )` que con un vector `(n_shape, 1)`.\n",
    "\n",
    "En `sklearn` la manera habitual de trabajar es:\n",
    "   * X → siempre 2D (n_samples, n_features)\n",
    "   * y → normalmente 1D (n_samples,), no columna\n",
    "\n",
    "Muchos errores vienen de usar `y.reshape(-1,1)` cuando el modelo espera un vector 1D.\n",
    "\n",
    "Si tu código no emplea `sklearn` asegurate de que la elección que hagas se mantenga después de cada operación. \n",
    "\n",
    "#### Control de dimensiones en NumPy: `reshape()`, `ravel()` y `flatten()`\n",
    "\n",
    "Cuando trabajamos con operaciones algebraicas vectorizadas (producto matricial, broadcasting, descenso de gradiente, etc.), **controlar la forma (`shape`) de los arrays es fundamental**.\n",
    "\n",
    "Recordatorio:\n",
    "- `(n,)` → vector 1D (sin orientación explícita)\n",
    "- `(n,1)` → vector columna\n",
    "- `(1,n)` → vector fila\n",
    "- `(n,m)` → matriz\n",
    "\n",
    "   - `reshape()`: Permite cambiar la forma del array **sin modificar los datos**.\n",
    "   - `ravel()`: Convierte un array en un vector 1D.\n",
    "       ``` python\n",
    "        A = np.array([[1,2],[3,4]])\n",
    "        A.ravel()   # → array([1,2,3,4])\n",
    "        ```\n",
    "   - `flatten()`: También convierte a 1D pero **crea una copia de los datos** (menos eficiente pero más seguro)\n",
    "       ``` python\n",
    "        A = np.array([[1,2],[3,4]])\n",
    "        A.flatten()   # → array([1,2,3,4])\n",
    "        ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ecuación Normal.\n",
    "\n",
    "Empezamos con la ecuación normal:\n",
    "$$\n",
    "\\boldsymbol{X}^T\\boldsymbol{X}\\Theta  - \\boldsymbol{X}^TY = 0\n",
    "$$\n",
    "\n",
    "Primero programamos dos funciones:\n",
    "\n",
    "* `normal_equation()`: A partir de los datos de entrada guardados en una matriz $X$ (sin la columna de 1's) y las etiquetas en el vector $Y$ calcula los coeficientes $\\Theta$.\n",
    "* `predicted()`: Una vez conocidos los coeficientes, devuelve la predicción dado un conjunto de datos de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(X,y):\n",
    "    \"\"\"\n",
    "    X: el conjunto de datos de entrada en la matriz X(m,n)\n",
    "        m: número de datos. \n",
    "        n: número de variables predictoras o atributos.\n",
    "    y: Vector con las imagenes de los datos de entrada conocidas. \n",
    "\n",
    "    Resuelvo la ecuación normal (X^T)X Theta = (X^T)Y\n",
    "    Return Theta: vector de coeficientes de la regresión lineal\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # El primer paso será añadir la columna de 1's a los datos\n",
    "    # Puedes usar la funcion de numpy np.column_stack((v,M)) que añade v como columna de M a la izquierda\n",
    "    v = np.ones((X.shape[0],1))\n",
    "    #***** TU CODIGO AQUI ********* (1 línea)\n",
    "    X_1 = np.column_stack((v,X))\n",
    "    #***** TU CODIGO AQUI *********\n",
    "\n",
    "    # Construye la matriz (X^T)X y el vector (X^T)Y donde X es la matriz amplida con la columna de 1's\n",
    "\n",
    "    #***** TU CODIGO AQUI ********* (2 líneas)\n",
    "    A = X_1.T@X_1\n",
    "    B = X_1.T@y\n",
    "    #***** TU CODIGO AQUI *********\n",
    "\n",
    "    # Resuelve el sistema lineal (X^T)X Theta = (X^T)Y usando la función adecuada de numpy\n",
    "\n",
    "    #***** TU CODIGO AQUI ********* (1 línea)\n",
    "    Theta =  np.linalg.inv(A)@B\n",
    "    #***** TU CODIGO AQUI *********  \n",
    "     \n",
    "    return Theta\n",
    "\n",
    "def predicted(X, Theta): # le pasa el conjunto de datos de entrada, vector theta calculado en normal ecuation y devuelve las predicciones\n",
    "    \"\"\"\n",
    "    X: el conjunto de datos de entrada en la matriz X(m,n)\n",
    "        m: número de datos. \n",
    "        n: número de variables predictoras o atributos.\n",
    "    Theta: vector de coeficientes Theta que devuelve la ecuación normal\n",
    "\n",
    "    Return Y_hat = X Theta\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    # El primer paso será añadir la columna de 1's a los datos\n",
    "    # Puedes usar la funcion de numpy np.column_stack((v,M)) que añade v como columna de M a la izquierda\n",
    "\n",
    "    v = np.ones((X.shape[0],1))\n",
    "    #***** TU CODIGO AQUI ********* (1 línea)\n",
    "    X_1 = np.column_stack((v,X))\n",
    "    #***** TU CODIGO AQUI *********\n",
    "\n",
    "    # Calcula el vector de predicciones asociado a los datos de entrada Y=X Theta siendo X es la matriz amplida con la columna de 1's\n",
    "    \n",
    "    #***** TU CODIGO AQUI ********* (1 línea)\n",
    "    Y_hat = X_1@Theta\n",
    "    #***** TU CODIGO AQUI *********\n",
    "  \n",
    "    return  Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplos a resolver:\n",
    "* #### Salarios:\n",
    "  Problema con 1 variable predictora (Años de experiencia) y una a predecir (Salario)\n",
    "      \n",
    "* #### Caso sintético de Sklearn:\n",
    "  Problema con 500 datos multivariables con 4 variables predictoras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Salario vs Años de Experiencia\n",
    "\n",
    "Datos de entrada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos desde el fichero CSV.\n",
    "# Modifica la ruta si lo necesitas\n",
    "\n",
    "datos = pd.read_csv('../Archivos/Salary_Data.csv')\n",
    "datos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(datos['YearsExperience'],datos['Salary'],s=30)\n",
    "plt.xlabel('Años de Experiencia')  # Set the label for x-axis\n",
    "plt.ylabel('Salario')  # Set the label for y-axis\n",
    "plt.title('Salario anual vs Años de Experiencia ')  # Set the title of the plot\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a ir paso a paso resolviendo el problema:\n",
    "\n",
    "* Calculamos los coeficientes de la regresión lineal $\\Theta$ llamando a la función `normal_equation()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datos['YearsExperience'].to_numpy().reshape(-1,1) # Convierte la serie en un vector columna\n",
    "y = datos['Salary'].to_numpy()                        # Convierte la serie en un vector (n_shape,)\n",
    "\n",
    "#***** TU CODIGO AQUI ********* (1 línea)\n",
    "# Theta = \n",
    "#***** TU CODIGO AQUI ********* \n",
    "\n",
    "print(Theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Probamos el modelo en un vector que contiene 6 datos nuevos (años de experiencia). Para ello llamamos a la función `predicted()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.random.uniform(0,12,(6,1))\n",
    "\n",
    "#***** TU CODIGO AQUI ********* (1 línea)\n",
    "# Y_pred = \n",
    "#***** TU CODIGO AQUI *********\n",
    "\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Representamos gráficamente los puntos originales, los puntos de prueba y la recta de regresión calculada\n",
    "\n",
    "*Precaución* Si falla el código asegurate de que `Y_pred` es un vector de la forma `(n_shape,)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_i = np.linspace(0,12,200).reshape((200,1))\n",
    "plt.figure(figsize=(6,6))\n",
    "# Puntos de entrenamiento\n",
    "sns.scatterplot(x=datos['YearsExperience'],y=datos['Salary'], marker=\"o\", label='Datos originales')\n",
    "# Puntos de prueba\n",
    "sns.scatterplot(x=X_test[:,0],y=Y_pred[:], color=\"r\",marker=\"s\", label='Predicciones')\n",
    "# Recta de regresión\n",
    "sns.lineplot(x=X_i[:,0], y=predicted(X_i, Theta)[:], color='green', label='Recta de aproximación lineal')\n",
    "plt.xlabel('Años de Experiencia')  # Set the label for x-axis\n",
    "plt.ylabel('Salario')  # Set the label for y-axis\n",
    "plt.title('Salario anual vs Años de Experiencia ')  # Set the title of the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Caso SKlearn\n",
    "\n",
    "En la libreria `Scikit-Learn` existen funciones para generar conjuntos de datos de forma artificial que utilizar para validar nuestros modelos.\n",
    "Vamos a empezar con un caso de regresión lineal con 500 datos cada uno de ellos con 4 variables de entrada.\n",
    "\n",
    "* Cómo interpretar el parámetro `noise=20`:\n",
    "Noise añade ruido gaussiano a las salidas del modelo lineal generado. En este caso, el ruido sigue una distribución normal con una desviación estándar de 20.\n",
    "Esto significa que, en promedio, los valores de y generados estarán desviados por alrededor de 20 unidades respecto a la verdadera relación lineal subyacente.\n",
    "\n",
    "* MSE esperado\n",
    "Un MSE esperable debería estar aproximadamente alrededor de la varianza del ruido introducido. Dado que especificaste noise=20, la varianza del ruido sería $20^2=400$. Esto te da una referencia de cuál sería el MSE mínimo esperable, ya que el modelo lineal tratará de capturar la relación subyacente, pero no podrá reducir el error por debajo del nivel de ruido introducido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.make_regression(n_samples=500, n_features=4, noise=20, random_state=4)\n",
    "\n",
    "n_samples, n_features = np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### División en Train/test\n",
    "\n",
    "Lo primero que haremos será dividir el conjunto de datos de entrada en dos subconjuntos. Uno que llamaremos `Train` lo usaremos para crear el modelo lineal. El resto de datos de entrada formarán el `Test`, desconocido para el modelo, que emplearemos para ver como de bien aproxima el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(0.8*n_samples)\n",
    "order = list(range(n_samples))\n",
    "np.random.shuffle(order)\n",
    "\n",
    "X_shuffle = X[order,:]\n",
    "y_shuffle = y[order]\n",
    "\n",
    "X_train = X_shuffle[:n_train, :]\n",
    "y_train = y_shuffle[:n_train] \n",
    "\n",
    "X_test  = X_shuffle[n_train:, :]\n",
    "y_test  = y_shuffle[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a ir paso a paso resolviendo el problema:\n",
    "\n",
    "* Calculamos los coeficientes de la regresión lineal $\\Theta$ llamando a la función `normal_equation()` sobre el conjunto de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#***** TU CODIGO AQUI ********* (1 línea)\n",
    "# Theta = \n",
    "#***** TU CODIGO AQUI ********* \n",
    "\n",
    "print(Theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Probamos el modelo en los datos de test. Para ello llamamos a la función `predicted()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***** TU CODIGO AQUI ********* (1 línea)\n",
    "# y_pred = \n",
    "#***** TU CODIGO AQUI ********* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Calculamos el MSE cometido en el conjunto de datos de test. Para ello implementa:\n",
    "$$\n",
    "J(\\Theta) = \\frac{1}{m} \\sum_{j=1}^m (\\hat{y}^j-y^j)^2 \n",
    "$$\n",
    "Intenta vectorizar la operación lo más posible. `y_pred` e `y_test` son vectores de la misma longitud. Puedes operar elemento a elemento para calcular $(\\hat{y}^j-y^j)^2 $ y sumar las componentes del vector resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo del error\n",
    "\n",
    "\n",
    "#***** TU CODIGO AQUI ********* (1 línea)\n",
    "# mse_test = \n",
    "#***** TU CODIGO AQUI ********* \n",
    "\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Por último representamos graficamente las predicciones frente a los valores reales. El error en cada dato es lo que se desvía de la diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=y_test,y=y_pred)\n",
    "min_val = min(y_test.min(), y_pred.min())  # Valor mínimo para la diagonal\n",
    "max_val = max(y_test.max(), y_pred.max())  # Valor máximo para la diagonal\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label=\"Línea ideal (y=x)\")\n",
    "plt.xlabel('Valores reales')\n",
    "plt.ylabel('Predicción')\n",
    "plt.title('Valor real vs. Predicción lineal en Test')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descenso de Gradiente.\n",
    "\n",
    "\n",
    "Vamos ahora a implementar la función que halle los coeficientes de la regresión usando descenso de gradiente:\n",
    "\n",
    "$$\n",
    "\\Theta^{k+1} = \\Theta^k - \\alpha\\left( \\boldsymbol{X}^T\\boldsymbol{X}\\Theta^k  - \\boldsymbol{X}^TY\\right)\n",
    "$$\n",
    "\n",
    "Para ello programaremos la función: `batch_gradient_descent(X,y,learning_rate = 0.0001, n_iters = 100)` que devuelve los pesos $\\Theta$ dados:\n",
    "\n",
    "* `X`: Matriz de datos de entrada $\\boldsymbol{X}$.\n",
    "* `y`: Vector de etiquetas $Y$ para esos datos de entrada.\n",
    "* `learning_rate`: tasa de aprendizaje $\\alpha$.\n",
    "* `n_iters`: número de iteraciones del descenso de gradiente. Se suele llamar *épocas* o `epochs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_descent(X,y,learning_rate = 0.001, n_iters = 100):\n",
    "    \"\"\"\n",
    "    X: el conjunto de datos de entrada en la matriz X(m,n)\n",
    "        m: número de datos. \n",
    "        n: número de variables predictoras o atributos.\n",
    "    y: Vector con las imagenes de los datos de entrada conocidas.\n",
    "    learning_rate: Tasa de aprendizaje. Por defecto 0.0001\n",
    "    n_iters: Numero de iteraciones o épocas del proceso iterativo. Por defecto 100 \n",
    "\n",
    "    Evaluo n_iters:\n",
    "        Theta^k+1 = Theta^k - learning_rate (2/m)(X^T(X Theta^k- Y)) \n",
    "    partiendo de un Theta^0 aleatorio\n",
    "    \n",
    "    Return Theta: vector de coeficientes de la regresión lineal\n",
    "    \"\"\"    \n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # Empezamos con un valor aleatorio Theta_0.\n",
    "    # Puedes usar la función Theta = np.random.randn(n_features+1) * 0.01 \n",
    "    # O desde numpy 1.17: \n",
    "    # rng = np.random.default_rng(seed=42)\n",
    "    # Theta = rng.standard_normal(n_features+1) * 0.01 \n",
    "\n",
    "    #***** TU CODIGO AQUI ********* (1 línea)\n",
    "    # Theta = \n",
    "    #***** TU CODIGO AQUI ********* \n",
    "\n",
    "    # A continuación añadimos la columna de 1's a los datos\n",
    "    # Puedes usar la funcion de numpy np.column_stack((v,M)) que añade v como columna de M a la izquierda\n",
    "\n",
    "    #***** TU CODIGO AQUI ********* (1 línea)\n",
    "    # X_1 =\n",
    "    #***** TU CODIGO AQUI *********\n",
    "  \n",
    "    # Iteramos por las epochs\n",
    "    for _ in range(n_iters):\n",
    "\n",
    "        # Implementa la operación matricial X^T(X Theta^k- Y)\n",
    "\n",
    "        #***** TU CODIGO AQUI ********* (1-2 línea)\n",
    "        # \n",
    "        #\n",
    "        #***** TU CODIGO AQUI ********* \n",
    "\n",
    "        # Actualiza el valor de Theta\n",
    "        #***** TU CODIGO AQUI ********* (1 línea)\n",
    "        # Theta = \n",
    "        #***** TU CODIGO AQUI ********* \n",
    "\n",
    "    return Theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo a resolver:\n",
    "#### Caso sintético de Sklearn:\n",
    "\n",
    "Mismo problema con 500 datos multivariables con 4 variables predictoras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### División en Train/test\n",
    "\n",
    "Ya tenemos el caso preparado puesto que lo resolvimos con las **ecuación normal**.\n",
    "En esta ocasión para hacer la división entre *Train* y *Test* utilizo la función `train_test_split` del módulo `sklearn.model_selection` en lugar de hacer la división nosotros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = datasets.make_regression(n_samples=500, n_features=4, noise=20, random_state=4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6543)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo de coeficientes de la regresión $\\Theta$\n",
    "\n",
    "Vamos a calcular los coeficientes usando tanto la **Ecuación Normal** (ya lo hicimos) como **Descenso de gradiente**. \n",
    "\n",
    "Los tiempos de cálculo no van a ser muy relevantes pues el caso que estamos probando es pequeño y el descenso de gradiente no va a suponer una mejora.\n",
    "\n",
    "Juega con los valores de `learning_rate` y `n_iters` para que los coeficientes sean *iguales*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Coeficientes calculados con la ecuacion normal\n",
    "start_time = time.time()\n",
    "\n",
    "#***** TU CODIGO AQUI ********* (1 línea)\n",
    "# Theta_normal = \n",
    "#***** TU CODIGO AQUI *********\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Tiempo de cálculo de coeficientes en ecuaciones normales: {elapsed_time:.5f} segundos\")\n",
    "print(Theta_normal)\n",
    "\n",
    "# Coeficientes calculados con descenso de gradiente\n",
    "start_time = time.time()\n",
    "\n",
    "#***** TU CODIGO AQUI ********* (1 línea)\n",
    "# Theta_gradient = \n",
    "#***** TU CODIGO AQUI ********* \n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Tiempo de cálculo de coeficientes en descenso de gradiente: {elapsed_time:.5f} segundos\")\n",
    "print(Theta_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción sobre los datos de test.\n",
    "\n",
    "Solamente vamos a trabajar con los coeficientes devueltos por el método de *descenso de gradiente*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***** TU CODIGO AQUI ********* (1 línea)\n",
    "# y_pred =\n",
    "#***** TU CODIGO AQUI ********* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo del error\n",
    "\n",
    "#***** TU CODIGO AQUI ********* (1 línea)\n",
    "# mse_test = \n",
    "#***** TU CODIGO AQUI ********* \n",
    "\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Por último representamos graficamente las predicciones frente a los valores reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=y_test,y=y_pred)\n",
    "min_val = min(y_test.min(), y_pred.min())  # Valor mínimo para la diagonal\n",
    "max_val = max(y_test.max(), y_pred.max())  # Valor máximo para la diagonal\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label=\"Línea ideal (y=x)\")\n",
    "plt.xlabel('Valores reales')\n",
    "plt.ylabel('Predicción')\n",
    "plt.title('Valor real vs. Predicción lineal en Test')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Polinómica.\n",
    "\n",
    "Vamos a generar un conjunto de datos en el intervalo $[-2, 2]$ a partir del polinomio\n",
    "\n",
    "$ f(x) = 3x^5 - 2x $\n",
    "\n",
    "El *dataset* estará formado por 30 puntos de la forma $X = \\{(x_i, f(x_i) + \\epsilon) \\}$ donde $\\epsilon$ será una variable aleatoria que tomará valores en el intervalo $[-\\frac{\\text{max}(f(x))}{10},\\frac{\\text{max}(f(x))}{10}]$\n",
    "\n",
    "Pretendemos que el modelo sea capaz de inferir que la dinámica que está representando sea el polinomio $ y_{pred}(x) = 3x^5 - 2x $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos un conjunto de datos en el intervalo [-2,2]\n",
    "a = -2.\n",
    "b = 2.\n",
    "n_points = 30\n",
    "x_i = np.random.rand(n_points)*(b-a) + a\n",
    "\n",
    "# generamos sus imagenes a partir de la función y(x) = 3*x^5 -2*x + ruido \n",
    "# El ruido lo genero normalmente distribuido entre \n",
    "y_x = 3*x_i**5 -2*x_i\n",
    "max_val = max(abs(y_x))\n",
    "\n",
    "ruido = np.random.normal(-(max_val)/10, max_val/10, n_points)\n",
    "y_i = y_x + ruido\n",
    "\n",
    "# Representamos los puntos iniciales\n",
    "plt.scatter(x_i, y_i)\n",
    "    \n",
    "plt.title('Puntos iniciales')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.xlim(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividimos el conjunto inicial en *Train/Test*\n",
    "\n",
    "Tomamos 12 puntos como conjunto de datos de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divido en training y test\n",
    "n_train = 12\n",
    "n_test = n_points-n_train\n",
    "order = list(range(len(x_i)))\n",
    "np.random.shuffle(order)\n",
    "\n",
    "x_train = np.array([x_i[i] for i in order[0:n_train]])\n",
    "y_train = np.array([y_i[i] for i in order[0:n_train]])\n",
    "\n",
    "x_test = np.array([x_i[i] for i in order[n_train:]])\n",
    "y_test = np.array([y_i[i] for i in order[n_train:]])\n",
    "\n",
    "\n",
    "# Representamos los puntos iniciales\n",
    "sns.scatterplot(x=x_i,y=y_i,  marker = 'o' , edgecolor='blue', facecolor='none', label= 'Puntos originales', s= 40 )\n",
    "sns.scatterplot(x=x_train,y=y_train,  marker = 'o' , color = 'red', label= 'Puntos entrenamiento', s= 20 )\n",
    "sns.scatterplot(x=x_test,y=y_test,  marker = 'o' , color = 'black', label= 'Puntos test', s= 20 )\n",
    "\n",
    "plt.title('Puntos ')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.xlim(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La manera en que vamos a calcular el polinomio de regresión de un determinado orden $p$ va a ser generar la matriz de datos sabiendo que sus columnas son potencias de orden creciente del vector con los datos originales:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{X} = \\begin{pmatrix}\n",
    " x_1 & x_1^2 & \\dots & x_1^p\\\\\n",
    " x_2 & x_2^2 & \\dots & x_2^p\\\\\n",
    "\\vdots & \\vdots & \\dots & \\vdots\\\\\n",
    " x_m & x_m^2 & \\dots & x_m^p\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Esa matriz será el primer argumento de entrada en la función `normal_equation()` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo de coeficientes de la regresión $\\Theta$\n",
    "\n",
    "Vamos a calcular los coeficientes usando la **Ecuación Normal**. \n",
    "\n",
    "Para ello, antes de llamar a las ecuaciones genera la matriz X_train  (X mayúscula) a partir del  vector x_train  calculado en la celda anterior  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 5 # Orden polinómico\n",
    "\n",
    "#***** TU CODIGO AQUI ********* \n",
    "# X_train = \n",
    "#***** TU CODIGO AQUI *********\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Calculamos ahora los coeficientes del polinomio de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***** TU CODIGO AQUI ********* (1 línea)\n",
    "# Theta = \n",
    "#***** TU CODIGO AQUI *********\n",
    "print(Theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Se parecen a los del polinomio buscado? ¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dibujar el polinomio resultante \n",
    "\n",
    "Vamos a implementar una función de nombre `polinomio` que dado un vector de coeficientes de tamaño $p+1$ y conjunto de puntos $\\boldsymbol{x}$ devuelva el vector: \n",
    "$$\n",
    "h_\\Theta(\\boldsymbol{x}) = \\theta_0  + \\theta_1 \\boldsymbol{x} + \\theta_2 \\boldsymbol{x}^2 + \\theta_3 \\boldsymbol{x}^3 +  \\dots +  \\theta_p \\boldsymbol{x}^p\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polinomio(Theta, x):\n",
    "\n",
    "    #***** TU CODIGO AQUI *********\n",
    "    \n",
    "    \n",
    "    #***** TU CODIGO AQUI *********\n",
    "\n",
    "    return imagen\n",
    "\n",
    "x_value = np.linspace(a,b,300)\n",
    "y_value = polinomio(Theta,x_value)\n",
    "\n",
    "# Representamos los puntos iniciales\n",
    "sns.lineplot(x=x_value,y=y_value, label= 'Polinomio de grado ' +str(p) )\n",
    "sns.scatterplot(x=x_train,y=y_train,  marker = 'o' , color = 'red', label= 'Puntos entrenamiento', s= 20 )\n",
    "sns.scatterplot(x=x_i,y=y_i,  marker = 'o' , edgecolor='blue', facecolor='none', label= 'Puntos originales', s= 40 )\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Polinomio aproximador')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularización.\n",
    "\n",
    "De momento solo vamos a implementar la ecuación normal modificada para el caso de **Ridge** donde la función de error toma la forma:\n",
    "\n",
    "$$\n",
    "J(\\Theta) = \\dfrac{1}{m} \\displaystyle\\sum_{j=1}^m (h_\\Theta(\\boldsymbol{x^j})-y^j)^2 + \\dfrac{\\lambda}{m} \\displaystyle\\sum_{i=1}^{n} \\theta_i^2 \n",
    "$$\n",
    "\n",
    "y la ecuación normal se escribe como:\n",
    "$$\n",
    "\\left(X^TX +\\lambda D\\right)\\Theta = X^T Y  \\text{   con }\n",
    "$$\n",
    "\n",
    "$$\n",
    "D = \\begin{pmatrix}\n",
    "0 & 0 & 0 & \\dots & 0\\\\\n",
    "0 & 1 & 0 & \\dots & 0\\\\\n",
    "0 & 0 & 1 &  \\dots & 0\\\\\n",
    "\\vdots & \\vdots &  & \\dots & \\vdots\\\\\n",
    "0 & 0 & 0 & \\dots & 1\n",
    "\\end{pmatrix} \n",
    "\\hspace{0.5cm}\n",
    "D \\in \\mathbb{M}^{(n+1)\\times(n+1)}(\\mathbb{R})\n",
    "$$\n",
    "\n",
    "\n",
    "Implementaremos una función:\n",
    "\n",
    "* `normal_equations_ridge(X, y, alpha = 1.)`: Pensada para el caso de regresión lineal con un conjunto de `m` datos de entrada con `n` características siendo `alpha` el coeficiente de regularización ($\\lambda$ en la ecuación)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equations_ridge(X, y, alpha = 1.):\n",
    "    \"\"\"\n",
    "    X: el conjunto de datos de entrada en la matriz X(m,n)\n",
    "        m: número de datos. \n",
    "        n: número de variables predictoras o atributos.\n",
    "    y: Vector con las imagenes de los datos de entrada conocidas. \n",
    "    alpha: coeficiente de regularización\n",
    "\n",
    "    Resuelvo la ecuación normal [(X^T)X + alpha*D] Theta = (X^T)Y\n",
    "    Return Theta: vector de coeficientes de la regresión lineal\n",
    "    \"\"\"\n",
    "\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Construcción de la matriz de regularización D\n",
    "\n",
    "    #***** TU CODIGO AQUI ********* (2 líneas)\n",
    "    # D = \n",
    "\n",
    "    #***** TU CODIGO AQUI *********\n",
    "\n",
    "\n",
    "    # A continuación añadimos la columna de 1's a los datos\n",
    "    # Puedes usar la funcion de numpy np.column_stack((v,M)) que añade v como columna de M a la izquierda\n",
    "\n",
    "    #***** TU CODIGO AQUI ********* (1 línea)\n",
    "    \n",
    "    #***** TU CODIGO AQUI *********\n",
    "\n",
    "    # Construye la matriz (X^T)X + alpha*D y el vector (X^T)Y donde X es la matriz amplida con la columna de 1's\n",
    "\n",
    "    #***** TU CODIGO AQUI ********* (2 líneas)\n",
    "    \n",
    "\n",
    "    #***** TU CODIGO AQUI *********\n",
    "\n",
    "    # Resuelve el sistema lineal [(X^T)X + alpha*D] Theta = (X^T)Y usando la función adecuada de numpy\n",
    "\n",
    "    #***** TU CODIGO AQUI ********* (1 línea)\n",
    "    # Theta =  \n",
    "    #***** TU CODIGO AQUI *********\n",
    "    \n",
    "    return Theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generar datos donde veamos el efecto de la *Regularización*.\n",
    "\n",
    "Vamos a generar una matriz de datos con 100 muestras y 4 características. Para ver el efecto de la regularización las dos últimas características estarán fuertemente correlacionadas con las dos primeras.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar un dataset con 32 variables originales y 100 muestras\n",
    "X, y = datasets.make_regression(n_samples=100, n_features=2, noise=10, random_state=12)\n",
    "\n",
    "# Inducir colinealidad añadiendo variables dependientes de las originales  \n",
    "U = (0.95 * X[:, 0] + 0.05 * np.random.randn(100)).reshape((100,1))  # Fuerte correlación con X[:,0]\n",
    "V = (0.95 * X[:, 1] + 0.01 * np.random.randn(100)).reshape((100,1))  # Fuerte correlación con X[:,1]\n",
    "\n",
    "X = np.column_stack((X, U, V))\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalización de los datos\n",
    "\n",
    "Antes de hacer la división en *Train* y *Test* normalizo los datos de entrada.\n",
    "\n",
    "Vamos a aplicar *Standard Scaler* a cada variable \n",
    "$$\n",
    "X_{\\text{normalized}} = \\dfrac{X-\\mu}{\\sigma}\n",
    "$$\n",
    "siendo $\\mu$ la media y $\\sigma$ la desviación estandar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos los datos usando Standard Scaler\n",
    "\n",
    "# Paso 1: Calcula la media y la desviación estándar de cada columna de X\n",
    "\n",
    "#***** TU CODIGO AQUI ********* (2 líneas)\n",
    "# mean =\n",
    "# std = \n",
    "#***** TU CODIGO AQUI ********* \n",
    "\n",
    "# Paso 2: Normaliza los datos usando broadcasting\n",
    "\n",
    "#***** TU CODIGO AQUI ********* (1 línea)\n",
    "# X_normalized = \n",
    "#***** TU CODIGO AQUI ********* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Dividimos en *Train* y *Test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=6543)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo de los coeficientes de la regresión\n",
    "\n",
    "Vamos a calcular los coeficientes usando y sin usar la regularización para ver su efecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa la ecuación normal para hallar los coeficientes sin regularizar\n",
    "\n",
    "#***** TU CODIGO AQUI ********* (1 línea)\n",
    "# Theta_normal = \n",
    "#***** TU CODIGO AQUI ********* \n",
    "\n",
    "# Usa la ecuación normal con regularización de Ridge para hallar los coeficientes\n",
    "\n",
    "#***** TU CODIGO AQUI ********* (1 línea)\n",
    "# Theta_ridge = \n",
    "#***** TU CODIGO AQUI *********\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comparamos los coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# **Imprimir coeficientes**\n",
    "print(\"Coeficientes sin regularización:\", Theta_normal)\n",
    "print(\"Coeficientes con Ridge:\", Theta_ridge)\n",
    "\n",
    "# **Visualización**\n",
    "labels = [\"Intercepto\", \"X1\", \"X2\", \"X3\" , \"X4\"]\n",
    "x_pos = np.arange(len(labels))\n",
    "\n",
    "plt.bar(x_pos - 0.2, Theta_normal, width=0.4, label=\"Regresión lineal\", color=\"blue\")\n",
    "plt.bar(x_pos + 0.2, Theta_ridge, width=0.4, label=\"Ridge\", color=\"green\")\n",
    "plt.xticks(x_pos, labels)\n",
    "plt.ylabel(\"Valor de los coeficientes\")\n",
    "plt.title(\"Comparación de coeficientes con y sin Ridge\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción en el conjunto de *Test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***** TU CODIGO AQUI ********* (2 línea)\n",
    "# y_pred_ridge  = \n",
    "# y_pred_normal =\n",
    "#***** TU CODIGO AQUI ********* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error sin y con Regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo del error\n",
    "\n",
    "#***** TU CODIGO AQUI ********* (2 línea)\n",
    "# mse_test_normal = \n",
    "# mse_test_ridge  = \n",
    "#***** TU CODIGO AQUI ********* \n",
    "\n",
    "print(mse_test_normal)\n",
    "print(mse_test_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Por último representamos graficamente ambas predicciones frente a los valores reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=y_test,y=y_pred_normal, color = 'b', label='Regresión sin regularización')\n",
    "sns.scatterplot(x=y_test,y=y_pred_ridge, color = 'g', label='Regresión con regularización')\n",
    "min_val = min(y_test.min(), y_pred_normal.min(), y_pred_ridge.min())  # Valor mínimo para la diagonal\n",
    "max_val = max(y_test.max(), y_pred_normal.max(), y_pred_ridge.max())  # Valor máximo para la diagonal\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label=\"Línea ideal (y=x)\")\n",
    "plt.xlabel('Valores reales')\n",
    "plt.ylabel('Predicción')\n",
    "plt.title('Valor real vs. Predicción lineal en Test')\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titulo-propio-ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
